---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>
---

**Kangsan Kim (ÍπÄÍ∞ïÏÇ∞)** (kksan07 \[at] kaist \[dot] ac \[dot] kr), and here is my [CV (Curriculum Vitae)](assets/Curriculum_Vitae.pdf).

---

I am a Ph.D. student in the Graduate School of AI at KAIST ([MLAI lab](https://www.mlai-kaist.com)), fortunate to be advised by Prof. [Sung Ju Hwang](http://www.sungjuhwang.com). 

My research focuses on developing multimodal large language models (MLLMs) that understand the world and interact with humans through visual data. I have previously worked on video understanding and multimodal Retrieval-Augmented Generation (RAG). I am also interested in embodied AI models that operate on egocentric video and require spatial reasoning capabilities.

# üî• News
- *2025.07*: &nbsp;üóΩ Joined NYU as a visiting student under Prof. [Mengye Ren](https://mengyeren.com).
- *2025.05*: &nbsp;üìñ HoliSafe is released on [arXiv](https://www.arxiv.org/abs/2506.04704).
- *2025.05*: &nbsp;üéâ VideoRAG got accepted to ACL Findings 2025.
- *2025.04*: &nbsp;üìñ UniversalRAG is released on [arXiv](https://arxiv.org/abs/2504.20734).
- *2025.02*: &nbsp;üéâ VideoICL got accepted to CVPR 2025.

# üìù Publications 

- <font size="4"><b>HoliSafe: Holistic Safety Benchmarking and Modeling with Safety Meta Token for Vision-Language Model</b></font>
[[project page]](https://youngwanlee.github.io/holisafe/) [[paper]](https://www.arxiv.org/abs/2506.04704) [[code]](https://github.com/youngwanLEE/holisafe) <br>
&#x200B;Youngwan Lee, **Kangsan Kim**, Kwanyong Park, Ilchae Jung, Sujin Jang, Seanie Lee, Yong-Ju Lee, Sung Ju Hwang <br>
<span style="color:darkred">**Arxiv**</span> 2025

- <font size="4"><b>UniversalRAG: Retrieval-Augmented Generation over Corpora of Diverse Modalities and Granularities</b></font>
[[project page]](https://universalrag.github.io/) [[paper]](https://arxiv.org/abs/2504.20734) [[code]](https://github.com/wgcyeo/UniversalRAG) <br>
&#x200B;Woongyeong Yeo\*, **Kangsan Kim\***, Soyeong Jeong, Jinheon Baek, Sung Ju Hwang <br>
<span style="color:darkred">**Arxiv**</span> 2025

- <font size="4"><b>VideoRAG: Retrieval-Augmented Generation over Video Corpus</b></font>
[[paper]](https://arxiv.org/abs/2501.05874) [[poster]](assets/poster/VideoRAG.pdf) [[code]](https://github.com/starsuzi/VideoRAG) <br>
&#x200B;Soyeong Jeong\*, **Kangsan Kim\***, Jinheon Baek\*, Sung Ju Hwang <br>
Findings of the Association for Computational Linguistics (<span style="color:darkred">**ACL Findings**</span>) 2025

- <font size="4"><b>VideoICL: Confidence-based Iterative In-context Learning for Out-of-Distribution Video Understanding</b></font>
[[paper]](https://arxiv.org/abs/2412.02186) [[poster]](https://drive.google.com/file/d/1bSE0MZVCmNDr8i_FSfOsGmgKpLCaS9Kf/view?usp=sharing) [[code]](https://github.com/KangsanKim07/VideoICL) <br>
&#x200B;**Kangsan Kim\***, Geon Park\*, Youngwan Lee, Woongyeong Yeo, Sung Ju Hwang <br>
Conference on Computer Vision and Pattern Recognition (<span style="color:darkred">**CVPR**</span>) 2025

(*: equal contribution)

# üíª Experiences
- <b>Visiting Student, [New York University](https://www.nyu.edu)</b> <br>
*2025.07 - Current*, Brooklyn, NY, USA  <br>
Advisor: Prof. [Mengye Ren](https://mengyeren.com) <br>
Studying question answering over egocentric video streams from multiple embodied agents.

- <b>Computer Vision Engineer Intern, [B GARAGE](https://www.bgarage.ai/)</b> <br>
*2022.10 - 2023.07*, San Jose, CA, USA <br>
Developed an ultra-fast edge instance segmentation model that can segment anything in the warehouse.

- <b>Machine Learning(NLP) Scientist Intern, [NAVER](https://papago.naver.com/)</b> <br>
*2021.07 - 2021.10*, Remote <br>
Built and improved end-to-end Korean-English speech translation model.

# üìñ Educations
- *2024.03 - Current*, Ph.D. in Artificial Intelligence, Korea Advanced Institute of Science and Technology (KAIST).
- *2018.03 - 2024.02*, B.S. in Computer Science, Korea Advanced Institute of Science and Technology (KAIST). 

# üèÜ Honors and Awards
- *2023.06* Qualcomm-KAIST Innovation Award. 
- *2020.09* Dean‚Äôs List, College of Engineering. 

<!-- # üí¨ Invited Talks
- *2021.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \| [\[video\]](https://github.com/) -->